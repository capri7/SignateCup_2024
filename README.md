# SignateCup_2024
概要
本プロジェクトは、SignateCup 2024において旅行会社の保有する顧客データを用い、旅行パッケージの成約率を予測するモデルの構築を目的としています。コンペティションの参加を通じて、データサイエンスにおける前処理、特徴量エンジニアリング、モデリングの一連のプロセスを実践しました。本リポジトリでは、その全ての作業内容を共有しています。

## データの前処理
#### 欠損値の処理: 
データセット内の欠損値を分析し、適切な手法で補完または削除を行いました。
#### ノイズの修正: 
データの異常値やノイズを検出し、ロバストな分析が可能なように修正を加えました。
#### 異常値の検出と修正: 
異常値を検出し、トレンドから逸脱するデータポイントを修正することで、モデルの精度を向上させました。

## 特徴量エンジニアリング
新しい特徴量の作成: 顧客の属性や接触履歴を基に、目的変数との関連性が高いと考えられる新しい特徴量を作成しました。例えば、訪問回数に基づく顧客の関心度や、家族構成に関連する特徴量などを考案しました。

### 目的変数を使用した特徴量の試行: 
初期段階では目的変数を用いた特徴量を作成しましたが、データリークの可能性が示唆されたため、これらの特徴量は削除しています。

### エンコーディングとスケーリング: 
カテゴリカルデータに対してホットエンコーディングを行い、全ての数値データをスケーリングしました。これにより、モデルの学習効率を高めました。

## クラス不均衡への対応
このデータセットは、成約に至る顧客（クラス1）が少ない不均衡データセットでした。そのため、以下の手法を用いてクラス不均衡を補正しました。

#### SMOTE: 
クラス1のデータを合成することで、クラスバランスを改善しました。ただし、このアプローチでは十分な精度が得られませんでした。

#### Stratify: 
トレーニングデータとテストデータにおいて、クラスの割合を維持するためにstratify=yを設定しましたが、期待するほどの改善は見られませんでした。

## モデル構築と評価
以下の機械学習モデルを用いて成約率の予測を行いました。各モデルについて、ハイパーパラメータの調整や交差検証を行い、最適なパフォーマンスを引き出すよう努めました。

- RandomForest
- CatBoost
- XGBoost
- Gradient Boost
- Logistic Regression
- LightGBM
- SVC

## AUCスコア
各モデルのパフォーマンスを比較し、最も精度の高いモデルとしてXGBoostを選定しました。最終的に、ベストなモデルで得られたAUCスコアは 0.8236439 (暫定) です。

## 結果と今後の展望
今回のコンペティションでは、複数のアプローチを試行しましたが、クラス不均衡の問題や特徴量選定においてさらなる改善の余地があると感じました。
今後の課題としては、さらに高度な特徴量エンジニアリングや、異なるモデルのアンサンブルを活用した精度向上が考えられます。
また、業務での実務的な応用を意識し、より汎用性の高いモデルの開発を目指していきたいと思います。

## お問い合わせ
このリポジトリやプロジェクトに関するご質問やご意見がございましたら、お気軽にご連絡ください。
kazuehayakawa@gmail.com





